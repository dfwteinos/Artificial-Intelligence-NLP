{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple AI-II-HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vte6gdZ13TZc"
      },
      "source": [
        "# Main idea.\n",
        "\n",
        "The main idea for this project, is to develop a sentiment classifier using **feed-forward** neural network for the [Twitter sentiment analysis dataset](https://drive.google.com/file/d/1dTIWNpjlrnTQBIQtaGOh0jCRYZiAQO79/view). \n",
        "\n",
        "We'll do some expirements with all the possible hyperparameters, like the number of hidden layers, activation functions, loss functions, optimizers, etc. <!-- Also, we'll use pre-trained word embendding vectors, using [GloVe](https://nlp.stanford.edu/projects/glove/). -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3wDsekgzf_E"
      },
      "source": [
        "#(1) Libraries and files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FAEXY0TERGe",
        "outputId": "c5406ac0-b975-49b8-ef45-2b27103b8d4d"
      },
      "source": [
        "!pip install d2l==0.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting d2l==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/4f/d169ebbd3c686b6ade9cba78fa2730ba5583048b901cd3b2cf01b28ea651/d2l-0.15.0-py3-none-any.whl (59kB)\n",
            "\r\u001b[K     |█████▌                          | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.0) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.0) (1.19.4)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.0) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l==0.15.0) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.15.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.15.0) (2018.9)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.0) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.0) (5.0.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.0) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.0) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.0) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.15.0) (7.5.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.15.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->d2l==0.15.0) (1.15.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.15.0) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.15.0) (2.6.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.15.0) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.15.0) (5.3.5)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (0.2.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (4.7.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.15.0) (20.0.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.15.0) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.0) (2.11.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.0) (5.0.8)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.0) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.15.0) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (3.2.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.15.0) (0.6.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.15.0) (3.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.15.0) (0.2.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.15.0) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.15.0) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.15.0) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.15.0) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.15.0) (51.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->d2l==0.15.0) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->d2l==0.15.0) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.15.0) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.0) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.15.0) (20.8)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctZoU0jAzrPp",
        "outputId": "309a7150-18dd-4776-d197-a64478f16ead"
      },
      "source": [
        "#Importing all the libraries that we are going to need for this assignment.\n",
        "\n",
        "#Pandas\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import csv\n",
        "pd.set_option('display.max_rows', None)                                         #See all rows\n",
        "\n",
        "#Numpy\n",
        "import numpy  as np\n",
        "\n",
        "#Natural Language Toolkit\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer \n",
        "stop = stopwords.words('english')\n",
        "\n",
        "#Sklearn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer                     #tf-idf\n",
        "from sklearn.feature_extraction.text import CountVectorizer                     #BoW\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score           #To divide our data evenly\n",
        "from sklearn import preprocessing                                               #Create numeric categories using the LabelEncoder and fit-trasnsform pipeline\n",
        "from sklearn.feature_selection import SelectKBest, chi2                         #Select the best features from vocabulary\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#PyTorch\n",
        "\n",
        "from d2l import torch as d2l\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#Matplot\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdpX_PqW0-cP"
      },
      "source": [
        "# (2) Functions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63v91Uxa-106"
      },
      "source": [
        "These functions are for data cleaning and preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ksErh3A1FnV"
      },
      "source": [
        "def sum1forline(filename,nrows):                                                #Calculating the rows in a csv file\n",
        "    with open(filename) as f:\n",
        "        total_lines = sum(1 for line in f)\n",
        "        if ( total_lines > nrows ):\n",
        "          print(\"We have:\", total_lines ,\"rows in total and we've read:\",nrows,\"samples\")\n",
        "        else:\n",
        "          print(\"We have:\", total_lines ,\"rows in total and we've read:\",total_lines,\"samples\")\n",
        "\n",
        "\n",
        "\n",
        "def cleanText(tweets):\n",
        "  tweets['text'] = tweets['text'].apply(lambda x: str(x).lower())                                                 #Make the text in lowercase\n",
        "\n",
        "  tweets['text'] = tweets['text'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text().strip())                    #Removing HTML Tags\n",
        "\n",
        "  tweets['text'] = tweets['text'].apply(lambda x: RemoveSpecialCharacters(x))                                     #Remove special characters (#!@%*& etc)\n",
        "\n",
        "  tweets['text'] = tweets['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))   #Removing stopwords\n",
        "\n",
        "  tweets['text'] = tweets['text'].apply(lambda x: removeNumbers(x))                                               #Removing numbers\n",
        "\n",
        "  #Steeming: \"rained\" , \"raining\" , \"rain\" converting into: \"rain\".\n",
        "\n",
        "  tweets['text_tokens'] = tweets['text'].apply(lambda x: word_tokenize(x))\n",
        "  #Uncomment the next lines if you want to choose steeming over leematization\n",
        "\n",
        "  # <-->\n",
        "  tweets['text_tokens_final'] = tweets['text_tokens'].apply(lambda x: word_stemmer(x))\n",
        "  # <-->\n",
        "\n",
        "  #Leematization: \"rocks\" : rock , \"corpora\" : corpus, \"better\" : good.\n",
        "  #Comment the next line if you want to choose steeming over leematization\n",
        "\n",
        "  # <-->\n",
        "  # tweets['text_tokens_final'] = tweets['text_tokens'].apply(lambda x: word_lemmatizer(x))\n",
        "  # <-->\n",
        "\n",
        "  #Final text\n",
        "\n",
        "  tweets['final_text'] = tweets['text_tokens_final'].apply(lambda x: list2string(x))\n",
        "\n",
        "  tweets['final_text'] =  tweets['final_text'].apply(lambda x: re.sub(r\"\\b[a-zA-Z]\\b\", \"\", x))                      #Remove all the single characters from a string\n",
        "\n",
        "  tweets['final_text'] = tweets['final_text'].apply(lambda x: re.sub(' +', ' ', x))                                 #Replace multiple whitespaces\n",
        "\n",
        "  #Clean the csv file from odd columns\n",
        "  tweets = tweets.drop(['text', 'text_tokens', 'text_tokens_final'], axis=1)\n",
        "  \n",
        "  columns_titles = [\"final_text\",\"sentiment\"]\n",
        "  tweets=tweets.reindex(columns=columns_titles)\n",
        "\n",
        "  tweets.columns= ['text', 'sentiment']                        \n",
        "\n",
        "  return tweets\n",
        "\n",
        "def removeNumbers(text):\n",
        "  result = ''.join([i for i in text if not i.isdigit()])\n",
        "  return result\n",
        "\n",
        "def RemoveSpecialCharacters(x):\n",
        "\n",
        "  cleanString = re.sub('\\W+',' ', x )\n",
        "  cleanString= ' '.join(cleanString.split())\n",
        "  return cleanString\n",
        "\n",
        "def word_stemmer(text):\n",
        "    stem_text = [PorterStemmer().stem(i) for i in text]\n",
        "    return stem_text\n",
        "\n",
        "def word_lemmatizer(text):\n",
        "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
        "    return lem_text\n",
        "\n",
        "def list2string(list):\n",
        "  # initialize an empty string \n",
        "  str1 = \" \" \n",
        "    \n",
        "  # return string   \n",
        "  return (str1.join(list)) \n",
        "\n",
        "def Word_Vectorizer(X_train, Y_train, X_test, Y_test, method, kBestFeatures):   #Vectorization with feature selection\n",
        "    \n",
        "    y_train = Y_train\n",
        "    y_test  = Y_test\n",
        "\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(Y_train)\n",
        "    \n",
        "    #Y_train and Y_test form now and then , will have numeric values instead of strings\n",
        "    #Same for X_train and X_test\n",
        "\n",
        "    Y_train = le.transform(Y_train)\n",
        "    Y_test  = le.transform(Y_test)\n",
        "\n",
        "    vectorizer = method()\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_train_reduced = SelectKBest(chi2, k=kBestFeatures).fit_transform(X_train, y_train )\n",
        "\n",
        "    X_test  = vectorizer.transform(X_test)\n",
        "    X_test_reduced = SelectKBest(chi2, k=kBestFeatures).fit_transform(X_test, y_test)\n",
        "\n",
        "    return X_train_reduced, Y_train, X_test_reduced, Y_test\n",
        "    # return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def convert2Torch(X_train, X_test, Y_train, Y_test):\n",
        "  \n",
        "  X_train = X_train.toarray()\n",
        "  X_test  = X_test.toarray()\n",
        "  X_train = torch.from_numpy(X_train).to(device)\n",
        "  X_test  = torch.from_numpy(X_test).to(device)\n",
        "\n",
        "\n",
        "  Y_train = np.array([Y_train]).T\n",
        "\n",
        "  Y_test  = np.array([Y_test]).T\n",
        "\n",
        "  Y_train = torch.from_numpy(Y_train).to(device)\n",
        "  Y_test  = torch.from_numpy(Y_test).to(device)\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "def loadGloveModel(File):\n",
        "  print(\"Loading Glove Model\")\n",
        "\n",
        "  f = open(File,'r')\n",
        "\n",
        "  gloveModel = {}\n",
        "\n",
        "  for line in f:\n",
        "  \n",
        "    splitLines = line.split()\n",
        "    word = splitLines[0]\n",
        "    wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
        "    gloveModel[word] = wordEmbedding\n",
        "    print(len(gloveModel),\" words loaded!\")\n",
        "  \n",
        "  return gloveModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfqGK0ge-7SV"
      },
      "source": [
        "These functions are for creating our FF-Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7glcwmyOSnG0"
      },
      "source": [
        "class FeedForward_NN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "\n",
        "    super(FeedForward_NN, self).__init__()\n",
        "\n",
        "    # Linear Layer 1: Input Layer. fc stands for fully conected layer\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "    # 1st Activation Function\n",
        "    self.relu1 = nn.ReLU()\n",
        "    # self.sigmoid1 = nn.Sigmoid()\n",
        "\n",
        "    # Linear Layer 2: Hidden Layer.\n",
        "    self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    # 2nd Activation Function\n",
        "    self.relu2 = nn.ReLU()\n",
        "    # self.sigmoid2 = nn.Sigmoid()\n",
        "\n",
        "    # Linear Layer 3: Output Layer.\n",
        "    self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Linear 1:\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # 1st Activation\n",
        "    x = self.relu1(x)\n",
        "    # x = self.sigmoid1(x)\n",
        "\n",
        "    # Linear 2:\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    # 2nd Activation\n",
        "    x = self.relu2(x)\n",
        "    # x = self.sigmoid2(x)\n",
        "\n",
        "    #Linear 3:\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    # Output Activation Function\n",
        "    # output = nn.Softmax(dim=0)\n",
        "    output = nn.functional.softmax(x, dim=0)\n",
        "    \n",
        "    return output\n",
        "\n",
        "def visual_loss():\n",
        "  \n",
        "  plt.plot(iter,train_loss)\n",
        "  \n",
        "  plt.xlabel('Epochs')\n",
        "  \n",
        "  plt.ylabel('Train Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0zPmFKosZxC"
      },
      "source": [
        "These functions are for training our FF-Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7HW0qZtsd8d"
      },
      "source": [
        "def training(X_train, Y_train, num_epochs, optimizer, loss, net):\n",
        "\n",
        "  train_loss = [] \n",
        "  iter = []\n",
        "\n",
        "  train_iter = d2l.load_array((X_train, Y_train), batch_size)\n",
        "\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    for X, y in train_iter:\n",
        "\n",
        "      # Set the accumulated gradients to zero before starting backpro\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward Pass into the FF Neural Network\n",
        "      y_pred = net(X.float())\n",
        "      # print(y_pred)\n",
        "      # print(y)\n",
        "\n",
        "      # Compute Loss\n",
        "      loss_func = loss(y_pred, torch.argmax(y,1))\n",
        "      # loss_func = loss(y_pred,y)\n",
        "      # loss_func = loss(torch.argmax(y_pred, dim=1), y)\n",
        "\n",
        "      # Computing gradients\n",
        "      # Backward pass\n",
        "      loss_func.backward()\n",
        "\n",
        "      # Updating Parameters\n",
        "      optimizer.step()\n",
        "    \n",
        "    train_loss.append( loss_func.item() )\n",
        "    iter.append( epoch + 1 )\n",
        "    print(\"Epoch:\",epoch + 1,\"completed.\")\n",
        "    print(\"Training loss:\",loss_func.item(),\"\\n\")\n",
        "\n",
        "  return train_loss, iter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRCGerITPlIb"
      },
      "source": [
        "Here, the evaluation will take place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJpWOM-NPoTG"
      },
      "source": [
        "def evaluate(X_test, Y_test, net, batch_size):\n",
        "\n",
        "  test_iter = d2l.load_array((X_test, Y_test), batch_size)\n",
        "\n",
        "  ff_nn_val_predictions= []\n",
        "  real_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for X, y in test_iter:\n",
        "    \n",
        "      probs = net(X.float())\n",
        "      ff_nn_val_predictions.append(torch.argmax(probs,dim=1).cpu().numpy()[0])\n",
        "      real_labels.append(y.cpu().numpy()[0])\n",
        "\n",
        "  print(classification_report(ff_nn_val_predictions, real_labels))\n",
        "  print(\"Accuracy Score -> \",   accuracy_score(   ff_nn_val_predictions, real_labels))\n",
        "  print(\"Precision Score -> \",  precision_score(  ff_nn_val_predictions, real_labels, average='macro')*100)\n",
        "  print(\"Recall Score -> \",     recall_score(     ff_nn_val_predictions, real_labels, average='macro')*100)\n",
        "  print(\"F-Measure Score -> \",  f1_score(         ff_nn_val_predictions, real_labels, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t56KXJp3fDw"
      },
      "source": [
        "Last but not least, we'll use the given GPU from google colab in order to make our computations a bit faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuLUicTw3rKW"
      },
      "source": [
        "def use_cuda():\n",
        "\n",
        "  if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "  else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Device available for running: \")\n",
        "  print(device)\n",
        "  return device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ijXz1M1iiH"
      },
      "source": [
        "# (3) Data Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LNW_ew6z1s64",
        "outputId": "9538dae8-3022-4ecc-e641-700d32cc914a"
      },
      "source": [
        "#Loading and previewing the given dataset.\n",
        "\n",
        "#How much lines you want to read (Use this in order to save the given RAM)\n",
        "samples = 1000000\n",
        "\n",
        "LocationCSV = r'/content/SentimentTweets.csv'\n",
        "tweets = pd.read_csv(LocationCSV, low_memory=False , quoting=csv.QUOTE_NONE, encoding='utf-8',  warn_bad_lines=False, error_bad_lines=False, nrows=samples);   #Read csv file\n",
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>680949</td>\n",
              "      <td>0</td>\n",
              "      <td>2249621587</td>\n",
              "      <td>Fri Jun 19 22:41:08 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>sukumarpant</td>\n",
              "      <td>#brokenpromises...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>406741</td>\n",
              "      <td>0</td>\n",
              "      <td>2059003515</td>\n",
              "      <td>Sat Jun 06 16:03:21 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>MTMSparrow</td>\n",
              "      <td>David Carradine  so sad. Thai's law not sure i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1337108</td>\n",
              "      <td>4</td>\n",
              "      <td>2017466467</td>\n",
              "      <td>Wed Jun 03 08:26:14 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>itsmemcee</td>\n",
              "      <td>A @ 415 B @ 425. Tell your bro i say congrats!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1560887</td>\n",
              "      <td>4</td>\n",
              "      <td>2186457254</td>\n",
              "      <td>Mon Jun 15 18:52:04 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>jdfreivald</td>\n",
              "      <td>@littlefluffycat  Indeed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1466295</td>\n",
              "      <td>4</td>\n",
              "      <td>2064458395</td>\n",
              "      <td>Sun Jun 07 06:19:20 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>CrazyHan</td>\n",
              "      <td>Completed Race 4 Life in 58mins with girlies f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0      680949  ...                                #brokenpromises... \n",
              "1      406741  ...  David Carradine  so sad. Thai's law not sure i...\n",
              "2     1337108  ...    A @ 415 B @ 425. Tell your bro i say congrats! \n",
              "3     1560887  ...                          @littlefluffycat  Indeed.\n",
              "4     1466295  ...  Completed Race 4 Life in 58mins with girlies f...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "3HjkR-ag8RQA",
        "outputId": "8c7495b3-9bb6-4238-cea3-dbe837ddb848"
      },
      "source": [
        "sum1forline(LocationCSV,samples)  #Calculating the rows in a csv file (When the file it's fully read, rows we'll be 1.280.001)\n",
        "tweets = cleanCSV(tweets)         #Drop useless columns\n",
        "tweets = cleanText(tweets)        #Data Preprocessing/Text cleaning => Takes some time\n",
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have: 144509 rows in total and we've read: 144509 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>brokenpromis</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>david carradin sad thai law sure fowl play man...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tell bro say congrat</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>littlefluffycat inde</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>complet race life min girli work fun bloodi ho...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text sentiment\n",
              "0                                       brokenpromis  negative\n",
              "1  david carradin sad thai law sure fowl play man...  negative\n",
              "2                               tell bro say congrat  positive\n",
              "3                               littlefluffycat inde  positive\n",
              "4  complet race life min girli work fun bloodi ho...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb_RPX7n7ZUZ",
        "outputId": "8364b2ab-92b3-4c1d-c13d-945c3b338eb3"
      },
      "source": [
        "#Dividing the dataset into train and test.\n",
        "\n",
        "X = tweets['text']\n",
        "y = tweets['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)       #Splitting our dataset\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative    45201\n",
            "positive    43784\n",
            "Name: sentiment, dtype: int64\n",
            "negative    11253\n",
            "positive    10994\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fem47DfB5-MN"
      },
      "source": [
        "In order to minimize our vocabulary, we'll do some feature extraction. The selection of the k-best features though, will go through the chi2 filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uItQt-sLAG-K"
      },
      "source": [
        "kBestFeatures = 1000 \n",
        "vec_method    = TfidfVectorizer\n",
        "# vec_method    = CountVectorizer\n",
        "\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = Word_Vectorizer(X_train, y_train, X_test, y_test, vec_method, kBestFeatures)       #Vectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKM8F_l-DlIp"
      },
      "source": [
        "Now, we'll convert our data into the tensor representation for training.\n",
        "\n",
        "Our datasets have a sparse matrix form, meaning that the most elements in the matrix are zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIZvc3CeIcnH",
        "outputId": "38533983-bc86-44f6-8723-0ee793edc771"
      },
      "source": [
        "device = use_cuda()\n",
        "X_train, X_test, Y_train , Y_test = convert2Torch(X_train, X_test, Y_train, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n",
            "Device available for running: \n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXa15X0cDQfn"
      },
      "source": [
        "# (4) Training our FF Neural Network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTQ3urQ0UXkY"
      },
      "source": [
        "First of all, we need to initialize our model. In order to do this, we must compute 3 basic componets:\n",
        "\n",
        "\n",
        "1. *Input Dimension*.\n",
        "2. *Hidden Dimension*.\n",
        "3. *Output Dimension*.\n",
        "\n",
        "The first one is simply the number of features in our training dataset.\n",
        "\n",
        "The last one is also an easy one, we have only 2 labels for each comment: Negative/Positive. Thus, the output_dim will be **2**.\n",
        "\n",
        "Now, the number of the units in hidden layer varies. After some expirements, we choose **500** units.\n",
        "\n",
        "Last but not least, we choose 2 activation functions:\n",
        "\n",
        "\n",
        "\n",
        "*   For Hidden Layers: **ReLU** (or **Sigmoid**).\n",
        "*   For Output Layers: **Softmax**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSC6T4gdZZNz",
        "outputId": "57e77df7-d43d-4a1f-abea-696c337d4a53"
      },
      "source": [
        "input_size  = X_train.shape[1]\n",
        "hidden_size = 500\n",
        "output_size = 2\n",
        "\n",
        "net = FeedForward_NN(input_size, hidden_size, output_size)\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedForward_NN(\n",
              "  (fc1): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (fc3): Linear(in_features=500, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mspZoX2MXwU5"
      },
      "source": [
        "Now, let's configure the hyperparameters for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5kqX356X34Q"
      },
      "source": [
        "num_epochs    = 10          # Number of epochs\n",
        "learning_rate = 0.001       # Learning Rate\n",
        "batch_size    = 64          # After how many samples we'll change the weights\n",
        "# weight_decay  = 0.01        # L2 Penalty (Optional here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gxm98bwVZ35"
      },
      "source": [
        "Now, we must also choose which lost function we should use, and also the optimizer. After some tests, we decided that the best combination for our occasion is:\n",
        "\n",
        "\n",
        "*   Loss Function: **CrossEntropyLoss**\n",
        "*   Optimizer: **Adam**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wScmOqhZZqL"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "# loss = nn.MSELoss()\n",
        "# loss = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
        "# optimizer     = optim.SGD(net.parameters(), lr= learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cDsM71dcYvc"
      },
      "source": [
        "So now we are ready to train our model! Then, we'll use some graphic data representation and also we'll see how good scores we managed to have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XIZT2Bed2Xc",
        "outputId": "1c806d14-b534-47fe-b8f8-f21a5a670ed8"
      },
      "source": [
        "train_loss, iter = training(X_train, Y_train, num_epochs, optimizer, loss, net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 completed.\n",
            "Training loss: 0.6931471228599548 \n",
            "\n",
            "Epoch: 2 completed.\n",
            "Training loss: 0.6931471824645996 \n",
            "\n",
            "Epoch: 3 completed.\n",
            "Training loss: 0.6931471228599548 \n",
            "\n",
            "Epoch: 4 completed.\n",
            "Training loss: 0.6931471228599548 \n",
            "\n",
            "Epoch: 5 completed.\n",
            "Training loss: 0.6931473016738892 \n",
            "\n",
            "Epoch: 6 completed.\n",
            "Training loss: 0.6931471824645996 \n",
            "\n",
            "Epoch: 7 completed.\n",
            "Training loss: 0.6931471824645996 \n",
            "\n",
            "Epoch: 8 completed.\n",
            "Training loss: 0.6931473016738892 \n",
            "\n",
            "Epoch: 9 completed.\n",
            "Training loss: 0.6931471824645996 \n",
            "\n",
            "Epoch: 10 completed.\n",
            "Training loss: 0.6931471228599548 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdOmwEh9PsDX",
        "outputId": "65ae92c0-6ae1-46b1-a49a-b09bf112c160"
      },
      "source": [
        "evaluate(X_test, Y_test, net, batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.50      0.51       183\n",
            "           1       0.47      0.49      0.48       165\n",
            "\n",
            "    accuracy                           0.50       348\n",
            "   macro avg       0.50      0.50      0.50       348\n",
            "weighted avg       0.50      0.50      0.50       348\n",
            "\n",
            "Accuracy Score ->  0.49712643678160917\n",
            "Precision Score ->  49.682875264270606\n",
            "Recall Score ->  49.68206656731247\n",
            "F-Measure Score ->  49.662349255680546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lnetGaMKlJa",
        "outputId": "a31f56e7-49f1-47ab-a598-d953043ebd91"
      },
      "source": [
        "visual_loss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}