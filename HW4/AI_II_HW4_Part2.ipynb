{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-II-HW4-Part2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oF0VsoGKDe9"
      },
      "source": [
        "\n",
        "## 3) Q&A System."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGVPGnKcKLvj"
      },
      "source": [
        "In this section of the assignment, we are going to extract the best possible **answer** from the best paper we've got. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySJwyXIpLzgP"
      },
      "source": [
        "First, we're installing the huggingface transformers library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z8j7kCkL7Ak",
        "outputId": "c03eeb2a-df69-491a-ab60-05dab5804788"
      },
      "source": [
        "!pip install transformers==3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0jSKIQHHaER"
      },
      "source": [
        "For simplicity reasons, we are taking the answers that we've got in the previous notebook, and we'll save them 'hardcoded' in a list. You can see the answers in [this](https://colab.research.google.com/drive/18TZL6cDZUJ4m1Wlmh8u_a3AgX87yBDEQ#scrollTo=R7-KSNpVGODl) notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0HQgFJBiRVc"
      },
      "source": [
        "answers = ['Coronaviruses (CoVs) are a group of enveloped viruses with a large positive single-stranded RNA genome (âˆ¼26-32 kb in length) of the subfamily Coronavirinae under the family Coronaviridae. The complete genome of CoV contains five major open reading frames (ORFs) that encode replicase polyproteins (ORF1ab), spike glycoprotein (S), envelope protein (E), membrane protein (M), and nucleocapsid protein (N) flanked by a 5 -untranslated region (UTR) and a 3 -UTR. Currently, members of the subfamily Coronavirinae are classified into four genera, Alphacoronavirus, Betacoronavirus, Gammacoronavirus, and Deltacoronavirus (Fehr and Perlman, 2015; Su et al., 2016) . CoVs can cause upper and lower respiratory diseases, gastroenteritis, and central nervous system infections in a wide variety of avian and mammalian hosts. Some CoVs are human pathogens that cause mild to severe disease, including NL63 and 229E of the genus Alphacoronavirus, and severe acute respiratory syndrome CoV (SARS-CoV), Middle East respiratory syndrome CoV (MERS-CoV), OC43, and HKU1 of the genus Betacoronavirus (Dijkman and van der Hoek, 2009;',\n",
        "           'In December 2019, a new type viral pneumonia cases occurred in Wuhan, Hubei Province; and then named \"2019 novel coronavirus (2019-nCoV)\" by the World Health Organization (WHO) on 12 January 2020. For it is a never been experienced respiratory disease before and with infection ability widely and quickly, it attracted the worlds attention but without treatment and control manual. For the request from frontline clinicians and public health professionals of 2019-nCoV infected pneumonia management, an evidence-based guideline urgently needs to be developed. Therefore, we drafted this guideline according to the rapid advice guidelines methodology and general rules of WHO guideline development; we also added the first-hand management data of Zhongnan Hospital of Wuhan University. This guideline includes the guideline methodology, epidemiological characteristics, disease screening and population prevention, diagnosis, treatment and control (including traditional Chinese Medicine), nosocomial infection prevention and control, and disease nursing of the 2019-nCoV. Moreover, we also provide a whole process of a successful treatment case of the severe 2019-nCoV infected pneumonia and experience and lessons of hospital rescue for 2019-nCoV infections. This rapid advice guideline is suitable for the first frontline doctors and nurses, managers of hospitals and healthcare sections, community residents, public health persons, relevant researchers, and all person who are interested in the 2019-nCoV.In December 2019, the 2019 novel coronavirus (2019-nCoV) was discovered and identified in the viral pneumonia cases that occurred in Wuhan, Hubei Province, China; And then was named by the World Health Organization (WHO) on 12 January 2020. In the following month, the 2019-nCoV quickly spreading inside and outside of Hubei Province and even other countries. Whats more, the sharp increase of the case number caused widespread panic among the people.Medical professionals require an up-to-date guideline to follow when an urgent healthcare problem emerging.',\n",
        "           'Since December 2019, China has been experiencing a large outbreak of a novel coronavirus (2019-nCoV) which can cause respiratory disease and severe pneumonia. We estimated the basic reproduction number R0 of 2019-nCoV to be around 2.2 (90% high density interval: 1.4-3.8), indicating the potential for sustained human-to-human transmission. Transmission characteristics appear to be of similar magnitude to severe acute respiratory syndrome-related coronavirus (SARS-CoV) and pandemic influenza, indicating a risk of global spread.On 31 December 2019, the World Health Organization (WHO) was alerted about a cluster of pneumonia of unknown aetiology in the city of Wuhan, China [1, 2] . Only a few days later, Chinese authorities identified and characterised a novel coronavirus (2019-nCoV) as the causative agent of the outbreak . The outbreak appears to have started from a single or multiple zoonotic transmission events at a wet market in Wuhan where game animals and meat were sold and has resulted in 5,997 confirmed cases in China and 68 confirmed cases in several other countries by 29 January 2020 . Based on the number of exported cases identified in other countries, the actual size of the epidemic in Wuhan has been estimated to be much larger .',\n",
        "           'Background As the outbreak of coronavirus disease 2019 (COVID-19) progresses, epidemiological data are needed to guide situational awareness and intervention strategies. Here we describe efforts to compile and disseminate epidemiological information on COVID-19 from news media and social networks.As the outbreak of coronavirus disease 2019 (COVID- 19) is rapidly expanding in China and beyond, with the potential to become a worldwide pandemic, 1 real-time analyses of epidemiological data are needed to increase situational awareness and inform interventions. 2 Previously, real-time analyses have shed light on the transmissibility, severity, and natural history of an emerging pathogen in the first few weeks of an outbreak, such as with severe acute respiratory syndrome (SARS), the 2009 influenza pandemic, and Ebola. Analyses of detailed line lists of patients are particularly useful to infer key epidemiological parameters, such as the incubation and infectious periods, and delays between infection and detection, isolation, and reporting of cases. 3, 4 However, official individual patient data rarely become publicly available early on in an outbreak, when the information is most needed.Building on our previous experience collating news reports to monitor transmission of Ebola virus, 7 here we present an effort to compile individual patient information and subnational epidemic curves on COVID-19 from a variety of online resources.',\n",
        "           'Severe acute respiratory syndrome (SARS) is a new infectious disease caused by a novel coronavirus that leads to deleterious pulmonary pathological features. Due to its high morbidity and mortality and widespread occurrence, SARS has evolved as an important respiratory disease which may be encountered everywhere in the world. The virus was identified as the causative agent of SARS due to the efforts of a WHO-led laboratory network. The potential mutability of the SARS-CoV genome may lead to new SARS outbreaks and several regions of the viral genomes open reading frames have been identified which may contribute to the severe virulence of the virus. With regard to the pathogenesis of SARS, several mechanisms involving both direct effects on target cells and indirect effects via the immune system may exist. Vaccination would offer the most attractive approach to prevent new epidemics of SARS, but the development of vaccines is difficult due to missing data on the role of immune system-virus interactions and the potential mutability of the virus. Even in a situation of no new infections, SARS remains a major health hazard, as new epidemics may arise. Therefore, further experimental and clinical research is required to control the disease.Severe acute respiratory syndrome (SARS) is the first new infectious disease of this millennium. SARS has originated from Southern China at the end of 2002 and has a high mortality and morbidity. Within a period of six months beginning at the end of 2002, the disease has affected more than 8,000 people and killed nearly 800 . The disease poses a new threat for respiratory medicine and rep-resents a challenge for antiviral drug development and administration [2, 3] .SARS is caused by a novel, SARS-associated coronavirus (SARS-CoV) which has been identified by a World Health Organization (WHO)-led global laboratory network. The first cases of SARS were reported from a hospital in Hanoi, Vietnam, by Carlo Urbani, a WHO scientist who himself died from the disease . After reports from health authorities in Hong Kong on the outbreak of a new form of epidemical atypical pneumonia in public hospitals, the WHO issued a global alert on the disease.',\n",
        "           'In December 2019, a novel coronavirus, called COVID-19, was discovered in Wuhan, China, and has spread to different cities in China as well as to 24 other countries. The number of confirmed cases is increasing daily and reached 34,598 on 8 February 2020. In the current study, we present a new forecasting model to estimate and forecast the number of confirmed cases of COVID-19 in the upcoming ten days based on the previously confirmed cases recorded in China. The proposed model is an improved adaptive neuro-fuzzy inference system (ANFIS) using an enhanced flower pollination algorithm (FPA) by using the salp swarm algorithm (SSA). In general, SSA is employed to improve FPA to avoid its drawbacks (i.e., getting trapped at the local optima). The main idea of the proposed model, called FPASSA-ANFIS, is to improve the performance of ANFIS by determining the parameters of ANFIS using FPASSA. The FPASSA-ANFIS model is evaluated using the World Health Organization (WHO) official data of the outbreak of the COVID-19 to forecast the confirmed cases of the upcoming ten days. More so, the FPASSA-ANFIS model is compared to several existing models, and it showed better performance in terms of Mean Absolute Percentage Error (MAPE), Root Mean Squared Relative Error (RMSRE), Root Mean Squared Relative Error (RMSRE), coefficient of determination (R 2 ), and computing time. Furthermore, we tested the proposed model using two different datasets of weekly influenza confirmed cases in two countries, namely the USA and China. The outcomes also showed good performances.',\n",
        "           'As the Coronavirus (COVID-19) expands its impact from China, expanding its catchment into surrounding regions and other countries, increased national and international measures are being taken to contain the outbreak. The placing of entire cities in \"lockdown\" directly affects urban economies on a multi-lateral level, including from social and economic standpoints. This is being emphasised as the outbreak gains ground in other countries, leading towards a global health emergency, and as global collaboration is sought in numerous quarters. However, while effective protocols in regard to the sharing of health data is emphasised, urban data, on the other hand, specifically relating to urban health and safe city concepts, is still viewed from a nationalist perspective as solely benefiting a nations economy and its economic and political influence. This perspective paper, written one month after detection and during the outbreak, surveys the virus outbreak from an urban standpoint and advances how smart city networks should work towards enhancing standardization protocols for increased data sharing in the event of outbreaks or disasters, leading to better global understanding and management of the same.The novel Coronavirus outbreak, (previously known as the 2019-nCoV and later renamed COVID-19 during the writing of this manuscript) is leading to the closure of entire cities in China, and causing stringent measures to be taken in others. While in distant different continents, far from China where the virus was first reported, places are being placed on high alert. In Wuhan, where the virus broke, schools, roads and markets have been shut down . The same is true in Hong Kong, Beijing and Hubei Province amongst surrounding areas, as precautionary measures are being emphasized to ensure that the spread of the virus is minimized, and complete and accurate information on the virus is being obtained . However, the rate of spread of the virus and the uncertainties surrounding the entire situation has led the World Health Organization (WHO) on 30 January 2019 to declare the Coronavirus outbreak a \"Global Public Health Emergency\". WHO determined, however, not to declare the outbreak a \"Public Health Emergency of International Concern\" (PHEIC) which is a higher level of declaration.']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQof-Y-HpjHW"
      },
      "source": [
        "questions = [\"What are the coronoviruses?\", \n",
        "       \"What was discovered in Wuhuan in December 2019?\", \n",
        "       \"What is Coronovirus Disease 2019?\",\n",
        "       \"What is COVID-19?\",\n",
        "       \"What is caused by SARS-COV2?\",\n",
        "       \"Where was COVID-19 discovered?\",\n",
        "       \"How does coronavirus spread?\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BtrLAJMYoY"
      },
      "source": [
        "For Question Answering we use the BertForQuestionAnswering class from the transformers library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taxznKf8MdRS"
      },
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9xGxveYM6jF"
      },
      "source": [
        "Load the tokenizer as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_-525C3M7ar"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ5sdE2XLO24"
      },
      "source": [
        "This function below, takes a *question* string and an *answer_text* string (which contains the answer), and identifies the words within the *answer_text*, that are the answer. In the end, it prints out the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHbdn7eLB4K"
      },
      "source": [
        "def answer_question(question, answer_text):\n",
        "    '''\n",
        "    Takes a `question` string and an `answer_text` string (which contains the\n",
        "    answer), and identifies the words within the `answer_text` that are the\n",
        "    answer. Prints them out.\n",
        "    '''\n",
        "\n",
        "    # ======== Tokenize ========\n",
        "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
        "    input_ids = tokenizer.encode(question, answer_text)\n",
        "\n",
        "    # Report how long the input sequence is.\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    # ======== Set Segment IDs ========\n",
        "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    # The number of segment A tokens includes the [SEP] token istelf.\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    # The remainder are segment B.\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    # Construct the list of 0s and 1s.\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    # There should be a segment_id for every input token.\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    # ======== Evaluate ========\n",
        "    # Run our example question through the model.\n",
        "\n",
        "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
        "\n",
        "    # ======== Reconstruct Answer ========\n",
        "    # Find the tokens with the highest `start` and `end` scores.\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "\n",
        "    # Get the string versions of the input tokens.\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    # Start with the first token.\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    # Select the remaining answer tokens and join them with whitespace.\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "        \n",
        "        # If it's a subword token, then recombine it with the previous token.\n",
        "        if tokens[i][0:2] == '##':\n",
        "            answer += tokens[i][2:]\n",
        "        \n",
        "        # Otherwise, add a space then the token.\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "\n",
        "    print('Answer: \"' + answer + '\"')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1kZWAt_NQZj"
      },
      "source": [
        "Now, for each question we are going to print the answer-text.\n",
        "\n",
        "As we can see, the answers usually are in within the **first** period of each answer. So, we are going to *minimize* our answer's text a lot, in order to have better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_okwrztpli9"
      },
      "source": [
        "def QnA_System(questions,answers):\n",
        "\n",
        "  for qna in range(len(questions)):\n",
        "\n",
        "    print(\"\\n For Question: \", questions[qna] , \"we have: \\n\")\n",
        "    answer_question(questions[qna], answers[qna][:100])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdik1K0JOAKU",
        "outputId": "dccdf215-2af0-4a68-8c1e-f5dd964bd1b2"
      },
      "source": [
        "QnA_System(questions,answers)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " For Question:  What are the coronoviruses? we have: \n",
            "\n",
            "Query has 35 tokens.\n",
            "\n",
            "Answer: \"enveloped viruses\"\n",
            "\n",
            " For Question:  What was discovered in Wuhuan in December 2019? we have: \n",
            "\n",
            "Query has 36 tokens.\n",
            "\n",
            "Answer: \"a new type viral pneumonia\"\n",
            "\n",
            " For Question:  What is Coronovirus Disease 2019? we have: \n",
            "\n",
            "Query has 34 tokens.\n",
            "\n",
            "Answer: \"a large outbreak of a novel coronavirus\"\n",
            "\n",
            " For Question:  What is COVID-19? we have: \n",
            "\n",
            "Query has 33 tokens.\n",
            "\n",
            "Answer: \"outbreak of coronavirus disease 2019\"\n",
            "\n",
            " For Question:  What is caused by SARS-COV2? we have: \n",
            "\n",
            "Query has 34 tokens.\n",
            "\n",
            "Answer: \"severe acute respiratory syndrome\"\n",
            "\n",
            " For Question:  Where was COVID-19 discovered? we have: \n",
            "\n",
            "Query has 38 tokens.\n",
            "\n",
            "Answer: \"wuhan , china\"\n",
            "\n",
            " For Question:  How does coronavirus spread? we have: \n",
            "\n",
            "Query has 31 tokens.\n",
            "\n",
            "Answer: \"expanding\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}